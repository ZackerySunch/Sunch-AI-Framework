import zmq
import torch
import os
import json

class Expert:
    def __init__(self):
        with open("models_port.json", "r", encoding="utf-8") as file:
            port = json.load(file)  # æŠŠ JSON è½‰æˆ Python å­—å…¸

        os.environ["CUDA_VISIBLE_DEVICES"] = port["Expert(Coding)_Test.py"][0]  # è®“ Expert AI åªä½¿ç”¨ GPU 1
        print(f"Expert AI(Coding) é‹è¡Œåœ¨: {torch.cuda.get_device_name(int(port["Expert(Coding)_Test.py"][0]))}")


        # åˆå§‹åŒ– ZeroMQ é€šè¨Š
        context = zmq.Context()
        self.socket = context.socket(zmq.ROUTER)  # REP = Response
        self.socket.bind(f"tcp://*:{port["Expert(Coding)_Test.py"][1]}")  # ç›£è½ç«¯å£ï¼Œç­‰å¾… Decision AI é€£æ¥
        print(f"Expert AI(Coding) TCP/IP Port : {port["Expert(Coding)_Test.py"][1]}")
        print("Expert(Coding) AI å•Ÿå‹•ï¼Œç­‰å¾… Decision AI è«‹æ±‚...")

        self.main()
        
    def main(self):
        while True:
            # æ¥æ”¶ Decision AI çš„è«‹æ±‚
            client_id,message = self.socket.recv_multipart()
            print(f"Expert(Coding) AI å¾ {client_id} æ”¶åˆ°è«‹æ±‚ï¼š{message}")
            if client_id == b"Admin" and message == b"PING":
                print("æ¥æ”¶åˆ°Admin AI PINGï¼Œå›æ‡‰PONG")
                self.socket.send_multipart([client_id,b"PONG"])
            else:
                response =f"ğŸš€ ç™¼é€å›æ‡‰ï¼šclient_id={client_id}ï¼Œ æ­¤è¨Šæ¯ä¾†è‡ªExpert(Coding)".encode("utf-8")
                self.socket.send_multipart([client_id, response])
if __name__ == "__main__": 
    os.chdir(os.path.dirname(os.path.abspath(__file__)))
    Expert()