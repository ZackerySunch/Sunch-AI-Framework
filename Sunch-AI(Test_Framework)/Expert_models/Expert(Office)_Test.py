import zmq
import torch
import os
import json

class Expert:
    def __init__(self):
        with open("models_port.json", "r", encoding="utf-8") as file:
            port = json.load(file) 

        os.environ["CUDA_VISIBLE_DEVICES"] = port["Expert(Office)_Test.py"][0]  
        print(f"Expert AI(Office) é‹è¡Œåœ¨: {torch.cuda.get_device_name(int(port["Expert(Office)_Test.py"][0]))}")

        context = zmq.Context()
        self.socket = context.socket(zmq.ROUTER)
        self.socket.bind(f"tcp://*:{port["Expert(Office)_Test.py"][1]}") 
        print(f"Expert AI(Office) TCP/IP Port : {port["Expert(Office)_Test.py"][1]}")
        print("Expert(Office) AI å•Ÿå‹•ï¼Œç­‰å¾… Decision AI è«‹æ±‚...")

        self.main()

    def main(self):
        while True:
            # æ¥æ”¶ Decision AI çš„è«‹æ±‚
            client_id,message = self.socket.recv_multipart()
            print(f"Expert(Office) AI å¾ {client_id} æ”¶åˆ°è«‹æ±‚ï¼š{message}")

            if client_id == b"Admin" and message == b"PING":
                print("æ¥æ”¶åˆ°Admin AI PINGï¼Œå›æ‡‰PONG")
                self.socket.send_multipart([client_id,b"PONG"])
            else:
                response =f"ğŸš€ ç™¼é€å›æ‡‰ï¼šclient_id={client_id}ï¼Œ æ­¤è¨Šæ¯ä¾†è‡ªExpert(Office)".encode("utf-8")
                self.socket.send_multipart([client_id, response])
                
if __name__ == "__main__": 
    os.chdir(os.path.dirname(os.path.abspath(__file__)))
    Expert()